{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b04ceb70-640f-4b36-8e11-2eec851fe388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from textblob import TextBlob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "302ea5ce-c15e-435c-a02c-f324e53643de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerJourneyAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.journey_data = None\n",
    "        self.user_patterns = None\n",
    "        self.category_insights = None\n",
    "        self.processed_df = None  # Added to store processed dataframe\n",
    "        \n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"Preprocess the dataset for journey analysis.\"\"\"\n",
    "        # Create a copy to avoid modifying original data\n",
    "        processed_df = df.copy()\n",
    "        \n",
    "        # Calculate sentiment scores for reviews\n",
    "        processed_df['sentiment_score'] = processed_df['normalized_review'].apply(\n",
    "            lambda x: TextBlob(str(x)).sentiment.polarity\n",
    "        )\n",
    "        \n",
    "        # Add binary columns for journey touchpoints\n",
    "        processed_df['has_rating'] = processed_df['rating'].notna().astype(int)\n",
    "        processed_df['has_review'] = processed_df['normalized_review'].notna().astype(int)\n",
    "        \n",
    "        # Calculate price sensitivity\n",
    "        processed_df['price_sensitivity'] = (\n",
    "            processed_df['discount_percentage'] / \n",
    "            processed_df['actual_price']\n",
    "        ).fillna(0)\n",
    "        \n",
    "        return processed_df\n",
    "    \n",
    "    def analyze_user_patterns(self, df):\n",
    "        \"\"\"Analyze patterns in user behavior.\"\"\"\n",
    "        user_patterns = defaultdict(dict)\n",
    "        \n",
    "        # Aggregate user behavior metrics\n",
    "        user_metrics = df.groupby('user_id').agg({\n",
    "            'product_id': 'count',\n",
    "            'rating': ['mean', 'std'],\n",
    "            'sentiment_score': ['mean', 'std'],\n",
    "            'price_sensitivity': 'mean',\n",
    "            'category': lambda x: list(x.unique()),\n",
    "            'discount_percentage': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Flatten column names\n",
    "        user_metrics.columns = [\n",
    "            'user_id', 'total_interactions', 'avg_rating', 'rating_std',\n",
    "            'avg_sentiment', 'sentiment_std', 'price_sensitivity',\n",
    "            'categories', 'avg_discount'\n",
    "        ]\n",
    "        \n",
    "        # Calculate category preferences\n",
    "        for _, row in user_metrics.iterrows():\n",
    "            user_id = row['user_id']\n",
    "            user_patterns[user_id] = {\n",
    "                'total_interactions': row['total_interactions'],\n",
    "                'avg_rating': row['avg_rating'],\n",
    "                'rating_consistency': 1 - (row['rating_std'] / 5 if pd.notna(row['rating_std']) else 0),\n",
    "                'sentiment_consistency': 1 - (row['sentiment_std'] if pd.notna(row['sentiment_std']) else 0),\n",
    "                'price_sensitivity': row['price_sensitivity'],\n",
    "                'preferred_categories': row['categories'],\n",
    "                'discount_preference': row['avg_discount']\n",
    "            }\n",
    "        \n",
    "        return dict(user_patterns)\n",
    "    \n",
    "    def analyze_category_patterns(self, df):\n",
    "        \"\"\"Analyze patterns within product categories.\"\"\"\n",
    "        category_insights = {}\n",
    "        \n",
    "        for category in df['category'].unique():\n",
    "            category_data = df[df['category'] == category]\n",
    "            \n",
    "            # Calculate category metrics\n",
    "            category_insights[category] = {\n",
    "                'avg_rating': category_data['rating'].mean(),\n",
    "                'review_sentiment': category_data['sentiment_score'].mean(),\n",
    "                'price_sensitivity': (\n",
    "                    category_data['discount_percentage'].corr(category_data['rating'])\n",
    "                ),\n",
    "                'avg_discount': category_data['discount_percentage'].mean(),\n",
    "                'review_rate': category_data['has_review'].mean(),\n",
    "                'common_terms': self._extract_common_terms(\n",
    "                    category_data[category_data['sentiment_score'] > 0]['normalized_review']\n",
    "                )\n",
    "            }\n",
    "        \n",
    "        return category_insights\n",
    "    \n",
    "    def analyze_journey_factors(self, df):\n",
    "        \"\"\"Analyze factors influencing customer journey and satisfaction.\"\"\"\n",
    "        journey_factors = {\n",
    "            'rating_drivers': self._analyze_rating_drivers(df),\n",
    "            'review_patterns': self._analyze_review_patterns(df),\n",
    "            'price_impact': self._analyze_price_impact(df)\n",
    "        }\n",
    "        \n",
    "        return journey_factors\n",
    "    \n",
    "    def _analyze_rating_drivers(self, df):\n",
    "        \"\"\"Analyze factors that drive product ratings.\"\"\"\n",
    "        rating_drivers = {\n",
    "            'discount_correlation': df['discount_percentage'].corr(df['rating']),\n",
    "            'price_correlation': df['actual_price'].corr(df['rating']),\n",
    "            'sentiment_correlation': df['sentiment_score'].corr(df['rating'])\n",
    "        }\n",
    "        \n",
    "        # Analyze rating distribution by category\n",
    "        rating_by_category = df.groupby('category')['rating'].agg(['mean', 'std']).to_dict('index')\n",
    "        rating_drivers['category_performance'] = rating_by_category\n",
    "        \n",
    "        return rating_drivers\n",
    "    \n",
    "    def _analyze_review_patterns(self, df):\n",
    "        \"\"\"Analyze patterns in customer reviews.\"\"\"\n",
    "        review_patterns = {\n",
    "            'review_rate': df['has_review'].mean(),\n",
    "            'sentiment_distribution': {\n",
    "                'positive': (df['sentiment_score'] > 0).mean(),\n",
    "                'neutral': (df['sentiment_score'] == 0).mean(),\n",
    "                'negative': (df['sentiment_score'] < 0).mean()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Analyze review length impact\n",
    "        df['review_length'] = df['normalized_review'].str.len()\n",
    "        review_patterns['length_correlation'] = df['review_length'].corr(df['rating'])\n",
    "        \n",
    "        return review_patterns\n",
    "    \n",
    "    def _analyze_price_impact(self, df):\n",
    "        \"\"\"Analyze the impact of pricing on customer satisfaction.\"\"\"\n",
    "        price_impact = {\n",
    "            'discount_satisfaction': {\n",
    "                'high_discount': df[df['discount_percentage'] > df['discount_percentage'].median()]['rating'].mean(),\n",
    "                'low_discount': df[df['discount_percentage'] <= df['discount_percentage'].median()]['rating'].mean()\n",
    "            },\n",
    "            'price_range_performance': {}\n",
    "        }\n",
    "        \n",
    "        # Analyze performance by price range\n",
    "        df['price_quartile'] = pd.qcut(df['actual_price'], 4, labels=['budget', 'mid_low', 'mid_high', 'premium'])\n",
    "        price_range_metrics = df.groupby('price_quartile').agg({\n",
    "            'rating': 'mean',\n",
    "            'sentiment_score': 'mean',\n",
    "            'has_review': 'mean'\n",
    "        }).to_dict('index')\n",
    "        \n",
    "        price_impact['price_range_performance'] = price_range_metrics\n",
    "        \n",
    "        return price_impact\n",
    "    \n",
    "    def _extract_common_terms(self, reviews, top_n=5):\n",
    "        \"\"\"Extract most common terms from positive reviews.\"\"\"\n",
    "        if reviews.empty:\n",
    "            return []\n",
    "            \n",
    "        tfidf = TfidfVectorizer(\n",
    "            stop_words='english',\n",
    "            max_features=top_n,\n",
    "            ngram_range=(1, 2)\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            tfidf_matrix = tfidf.fit_transform(reviews.fillna(''))\n",
    "            feature_names = tfidf.get_feature_names_out()\n",
    "            return list(feature_names)\n",
    "        except:\n",
    "            return []\n",
    "    \n",
    "    def analyze_customer_journeys(self, df):\n",
    "        \"\"\"Main method to analyze customer journeys.\"\"\"\n",
    "        # Preprocess data\n",
    "        self.processed_df = self.preprocess_data(df)  # Store processed_df as instance variable\n",
    "        \n",
    "        # Perform analyses\n",
    "        self.user_patterns = self.analyze_user_patterns(self.processed_df)\n",
    "        self.category_insights = self.analyze_category_patterns(self.processed_df)\n",
    "        self.journey_factors = self.analyze_journey_factors(self.processed_df)\n",
    "        \n",
    "        return {\n",
    "            'user_patterns': self.user_patterns,\n",
    "            'category_insights': self.category_insights,\n",
    "            'journey_factors': self.journey_factors\n",
    "        }\n",
    "    \n",
    "    def get_user_journey_summary(self, user_id):\n",
    "        \"\"\"Get a summary of a specific user's journey.\"\"\"\n",
    "        if user_id not in self.user_patterns:\n",
    "            return None\n",
    "            \n",
    "        user_data = self.user_patterns[user_id]\n",
    "        \n",
    "        return {\n",
    "            'interaction_level': 'High' if user_data['total_interactions'] > 5 else 'Medium' if user_data['total_interactions'] > 2 else 'Low',\n",
    "            'satisfaction_level': 'High' if user_data['avg_rating'] > 4 else 'Medium' if user_data['avg_rating'] > 3 else 'Low',\n",
    "            'price_sensitivity': 'High' if user_data['price_sensitivity'] > 0.5 else 'Medium' if user_data['price_sensitivity'] > 0.2 else 'Low',\n",
    "            'preferred_categories': user_data['preferred_categories'],\n",
    "            'consistency': user_data['rating_consistency']\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2616ec6-94eb-4622-83f2-f46f98b78b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_customer_behavior(df):\n",
    "    \"\"\"Wrapper function to analyze customer behavior and generate insights.\"\"\"\n",
    "    analyzer = CustomerJourneyAnalyzer()\n",
    "    analysis_results = analyzer.analyze_customer_journeys(df)\n",
    "    \n",
    "    # Generate summary insights using processed_df instead of original df\n",
    "    summary = {\n",
    "        'overall_satisfaction': {\n",
    "            'average_rating': analyzer.processed_df['rating'].mean(),\n",
    "            'rating_distribution': analyzer.processed_df['rating'].value_counts().to_dict(),\n",
    "            'sentiment_distribution': {\n",
    "                'positive': (analyzer.processed_df['sentiment_score'] > 0).mean(),\n",
    "                'negative': (analyzer.processed_df['sentiment_score'] < 0).mean(),\n",
    "                'neutral': (analyzer.processed_df['sentiment_score'] == 0).mean()\n",
    "            }\n",
    "        },\n",
    "        'top_performing_categories': sorted(\n",
    "            analysis_results['category_insights'].items(),\n",
    "            key=lambda x: x[1]['avg_rating'],\n",
    "            reverse=True\n",
    "        )[:3],\n",
    "        'key_factors': {\n",
    "            'price_sensitivity': analysis_results['journey_factors']['price_impact'],\n",
    "            'review_patterns': analysis_results['journey_factors']['review_patterns']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return analyzer, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "941b2b85-78b9-4b0b-9f4f-ce8c2b51f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrame\n",
    "df = pd.read_csv('/Users/anithasmac/Projects/CustomerJourneyMapping/Featured_Amazon_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e45a0233-a6c0-432c-8b84-3196ad7eb58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Customer Journey Insights:\n",
      "Average Rating: 4.11\n",
      "\n",
      "Top Performing Categories:\n",
      "Computers&Accessories|Tablets: 4.60 average rating\n",
      "Electronics|HomeAudio|MediaStreamingDevices|StreamingClients: 4.50 average rating\n",
      "Electronics|Cameras&Photography|Accessories|Film: 4.50 average rating\n",
      "\n",
      "User Journey Summary for AG3D6O4STAQKAY2UVGEUV46KN35Q,AHMY5CWJMMK5BJRBBSNLYT3ONILA,AHCTC6ULH4XB6YHDY6PCH2R772LQ,AGYHHIERNXKA6P5T7CZLXKVPT7IQ,AG4OGOFWXJZTQ2HKYIOCOY3KXF2Q,AENGU523SXMOS7JPDTW52PNNVWGQ,AEQJHCVTNINBS4FKTBGQRQTGTE5Q,AFC3FFC5PKFF5PMA52S3VCHOZ5FQ:\n",
      "{'interaction_level': 'High', 'satisfaction_level': 'High', 'price_sensitivity': 'Low', 'preferred_categories': ['Computers&Accessories|Accessories&Peripherals|Cables&Accessories|Cables|USBCables'], 'consistency': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Analyze customer journeys\n",
    "analyzer, summary = analyze_customer_behavior(df)\n",
    "\n",
    "# Print overall insights\n",
    "print(\"\\nOverall Customer Journey Insights:\")\n",
    "print(f\"Average Rating: {summary['overall_satisfaction']['average_rating']:.2f}\")\n",
    "print(\"\\nTop Performing Categories:\")\n",
    "for category, metrics in summary['top_performing_categories']:\n",
    "    print(f\"{category}: {metrics['avg_rating']:.2f} average rating\")\n",
    "\n",
    "# Get specific user journey\n",
    "user_id = df['user_id'].iloc[0]\n",
    "user_journey = analyzer.get_user_journey_summary(user_id)\n",
    "print(f\"\\nUser Journey Summary for {user_id}:\")\n",
    "print(user_journey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a093a9d-46d4-4eba-abab-460c3e375e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
